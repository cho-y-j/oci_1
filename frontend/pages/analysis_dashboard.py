import streamlit as st
from frontend.database import (
    get_db_connection,
    save_analysis,
    load_existing_analysis,  # ì¶”ê°€
    save_analysis_state
)
from frontend.pages.respondent_analysis import (
    show_basic_status,
    show_department_distribution,
    show_gender_distribution,
    show_age_distribution,
    show_education_distribution,
    show_certification_distribution  # experience_distribution ëŒ€ì‹  certification_distributionìœ¼ë¡œ ë³€ê²½
)
from frontend.pages.oci_analysis import show_oci_analysis
from frontend.pages.cgs_analysis import show_cgs_analysis
import pandas as pd
from frontend.services.ai_analysis import (
    generate_department_analysis,
    generate_comprehensive_report  # ì¶”ê°€
)

def select_file():
    """íŒŒì¼ ì„ íƒ í•¨ìˆ˜"""
    conn = get_db_connection()
    
    # ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    files_df = pd.read_sql("""
        SELECT 
            file_id,
            file_name,
            uploaded_at,
            status
        FROM uploaded_files
        WHERE status = 'completed'
        ORDER BY uploaded_at DESC
    """, conn)
    
    if files_df.empty:
        st.warning("ì²˜ë¦¬ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
        return None
    
    # íŒŒì¼ ì„ íƒ ì˜µì…˜ ë§Œë“¤ê¸°
    file_options = files_df.apply(
        lambda x: f"{x['file_name']} (ì—…ë¡œë“œ: {x['uploaded_at'].strftime('%Y-%m-%d %H:%M')})", 
        axis=1
    ).tolist()
    
    selected = st.selectbox(
        "ë¶„ì„í•  íŒŒì¼ ì„ íƒ",
        options=file_options,
        index=0 if file_options else None
    )
    
    if selected:
        # ì„ íƒëœ íŒŒì¼ì˜ ID ë°˜í™˜ (intë¡œ ë³€í™˜)
        selected_idx = file_options.index(selected)
        return int(files_df.iloc[selected_idx]['file_id'])  # intë¡œ ëª…ì‹œì  ë³€í™˜
    
    return None

def show_analysis_dashboard():
    st.title("ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    
    # íŒŒì¼ ì„ íƒ
    file_id = select_file()
    if not file_id:
        st.warning("ë¶„ì„í•  íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return
    
    # íƒ­ êµ¬ì„±
    tab1, tab2, tab3, tab4 = st.tabs([
        "ì‘ë‹µì ë¶„ì„", 
        "OCI ë¶„ì„", 
        "CGS ë¶„ì„",
        "AI ì¢…í•©ë¶„ì„ ë¦¬í¬íŠ¸"
    ])
    
    with tab1:
        show_basic_status(file_id)
    with tab2:
        show_oci_analysis(file_id)
    with tab3:
        show_cgs_analysis(file_id)
    with tab4:
        show_comprehensive_report(file_id)

def show_comprehensive_report(file_id):
    st.subheader("AI ì¢…í•©ë¶„ì„ ë¦¬í¬íŠ¸")
    
    # ë¶„ì„ ê²°ê³¼ í™•ì¸
    conn = get_db_connection()
    analysis_count = pd.read_sql("""
        SELECT COUNT(*) as count 
        FROM analysis_results 
        WHERE file_id = %s AND analysis_text IS NOT NULL
    """, conn, params=[file_id]).iloc[0]['count']
    
    if analysis_count < 5:  # ìµœì†Œ 5ê°œì˜ ë¶„ì„ì´ í•„ìš”í•˜ë‹¤ê³  ê°€ì •
        st.warning("ë¶„ì„ ì €ì¥ì´ ë§ˆë¬´ë¦¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê° ë¶„ì„ íƒ­ì—ì„œ AI ë¶„ì„ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
        return
    
    # ë¶„ì„ ìš”ì²­ì‚¬í•­ ì…ë ¥
    analysis_request = st.text_area(
        "ë¶„ì„ ìš”ì²­ì‚¬í•­ (ì„ íƒì‚¬í•­)",
        placeholder="íŠ¹ë³„íˆ ë¶„ì„ì´ í•„ìš”í•œ ë¶€ë¶„ì´ë‚˜ ì¤‘ì ì ìœ¼ë¡œ ì‚´í´ë³¼ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.",
        height=100
    )
    
    # ê¸°ì¡´ ë¶„ì„ ë¶ˆëŸ¬ì˜¤ê¸°
    existing_analysis = load_existing_analysis(file_id, "comprehensive", "report")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        # ë¶„ì„ ë‚´ìš© í‘œì‹œ/í¸ì§‘ ì˜ì—­
        edited_text = st.text_area(
            "ì¢…í•© ë¶„ì„ ë‚´ìš©",
            value=existing_analysis if existing_analysis else "",
            height=500,
            key="comprehensive_analysis"
        )
    
    with col2:
        st.write("")
        st.write("")
        # AI ë¶„ì„ ìš”ì²­ ë²„íŠ¼
        if st.button("ğŸ¤– AI ë¶„ì„ ìš”ì²­", use_container_width=True):
            with st.spinner("AIê°€ ë¶„ì„ì„ ì§„í–‰ì¤‘ì…ë‹ˆë‹¤..."):
                analysis_text = generate_comprehensive_report(
                    file_id=file_id, 
                    requirements=analysis_request if analysis_request else None
                )
                st.session_state["comprehensive_analysis"] = analysis_text
                st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.experimental_rerun()
        
        st.write("")
        # ë¶„ì„ ì €ì¥ ë²„íŠ¼
        if st.button("ğŸ’¾ ë¶„ì„ ì €ì¥", use_container_width=True):
            save_analysis(file_id, "comprehensive", "report", edited_text)
            st.success("ë¶„ì„ ë‚´ìš©ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        st.write("")
        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        if edited_text:
            st.download_button(
                label="ğŸ“¥ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ",
                data=edited_text.encode('utf-8'),
                file_name=f"AI_ì¢…í•©ë¶„ì„ë¦¬í¬íŠ¸_{file_id}.txt",
                mime="text/plain",
                use_container_width=True
            )

def show_department_analysis(file_id):
    # ìƒë‹¨ ë¶„ì„ í•­ëª© ì„ íƒ
    analysis_items = [
        "ë¶€ì„œë³„ ë¶„í¬ë„",  # ì²« ë²ˆì§¸ í•­ëª©ìœ¼ë¡œ ì„¤ì •
        "ì„±ë³„ ë¶„í¬", 
        "ì—°ë ¹ëŒ€ ë¶„í¬",
        "í•™ë ¥ ë¶„í¬",
        "ì „ê³µ ë¶„í¬",
        "ê²½ë ¥ ë¶„í¬",
        "ë¶€ì„œë³„ OCI í‰ê· ",
        "ë¶€ì„œë³„ CGS í‰ê· "
    ]
    selected_item = st.selectbox("ë¶„ì„ í•­ëª©", analysis_items)
    
    # 2ë‹¨ ë ˆì´ì•„ì›ƒ
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # ë°ì´í„° í…Œì´ë¸”ê³¼ ì°¨íŠ¸
        if selected_item == "ë¶€ì„œë³„ ë¶„í¬ë„":
            show_department_distribution(file_id)
        elif selected_item == "ì„±ë³„ ë¶„í¬":
            show_gender_distribution(file_id)
        # ... ë‹¤ë¥¸ ë¶„ì„ í•­ëª©ë“¤
    
    with col2:
        # AI ë¶„ì„ ìš”ì•½
        st.subheader("AI ë¶„ì„ ìš”ì•½")
        show_ai_analysis(file_id, "department", selected_item)

def show_ai_analysis(file_id, analysis_type, item):
    # ê¸°ì¡´ ë¶„ì„ ê°€ì ¸ì˜¤ê¸°
    conn = get_db_connection()
    cur = conn.cursor()
    
    cur.execute("""
        SELECT analysis_text 
        FROM analysis_results 
        WHERE file_id = %s AND analysis_type = %s AND analysis_item = %s
    """, (file_id, analysis_type, item))
    
    result = cur.fetchone()
    existing_analysis = result[0] if result else ""
    
    # í¸ì§‘ ê°€ëŠ¥í•œ ë¶„ì„ í…ìŠ¤íŠ¸
    edited_analysis = st.text_area(
        "",
        value=existing_analysis,
        height=400,
        placeholder="AI ë¶„ì„ ê²°ê³¼ë‚˜ ìˆ˜ë™ ë¶„ì„ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”."
    )
    
    # ì €ì¥ ë²„íŠ¼
    if st.button("ë¶„ì„ ë‚´ìš© ì €ì¥", use_container_width=True):
        save_analysis(file_id, analysis_type, item, edited_analysis)
        st.success("ë¶„ì„ ë‚´ìš©ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def save_to_powerbi_table(file_id, table_name, df):
    """PowerBIìš© í…Œì´ë¸” ì €ì¥"""
    conn = get_db_connection()
    cur = conn.cursor()
    
    # í…Œì´ë¸” ìƒì„± (ì—†ëŠ” ê²½ìš°)
    create_powerbi_table(cur, table_name, df)
    
    # ë°ì´í„° ì €ì¥
    for _, row in df.iterrows():
        columns = ", ".join(df.columns)
        placeholders = ", ".join(["%s"] * len(df.columns))
        
        cur.execute(f"""
            INSERT INTO powerbi_{table_name} (file_id, {columns})
            VALUES (%s, {placeholders})
            ON CONFLICT (file_id, department, gender) 
            DO UPDATE SET 
                count = EXCLUDED.count,
                percentage = EXCLUDED.percentage
        """, (file_id, *row))
    
    conn.commit()
    cur.close()
    conn.close()

def create_powerbi_table(cur, table_name, df):
    """PowerBIìš© í…Œì´ë¸” ìƒì„±"""
    columns = ", ".join([
        f"{col} {get_sql_type(df[col])}"
        for col in df.columns
    ])
    
    cur.execute(f"""
        CREATE TABLE IF NOT EXISTS powerbi_{table_name} (
            id SERIAL PRIMARY KEY,
            file_id INTEGER REFERENCES uploaded_files(file_id),
            {columns},
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(file_id, department, gender)
        )
    """)

def get_sql_type(series):
    """pandas ë°ì´í„°íƒ€ì…ì„ PostgreSQL íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
    dtype = series.dtype
    if dtype == 'int64':
        return 'INTEGER'
    elif dtype == 'float64':
        return 'DECIMAL(10,2)'
    else:
        return 'VARCHAR(100)'

def save_analysis(file_id, analysis_type, item, analysis_text):
    """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
    conn = get_db_connection()
    cur = conn.cursor()
    
    cur.execute("""
        INSERT INTO analysis_results 
            (file_id, analysis_type, analysis_item, analysis_text, created_at)
        VALUES (%s, %s, %s, %s, CURRENT_TIMESTAMP)
        ON CONFLICT (file_id, analysis_type, analysis_item)
        DO UPDATE SET 
            analysis_text = EXCLUDED.analysis_text,
            updated_at = CURRENT_TIMESTAMP
    """, (file_id, analysis_type, item, analysis_text))
    
    conn.commit()
    cur.close()
    conn.close() 